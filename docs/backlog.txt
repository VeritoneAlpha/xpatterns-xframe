xFrames backlog
---------------

Core feature backlog
--------------------

XFrame
------
support datetime as column type  (2d)
(estimate includes all items marked * below)

support array.array as column type (1d)

XFrame.read_csv_with_errors (not implemented) (1d)
	about 20 test cases

XFrame.print_rows (to be tested) (2h)
	empty XFrame
	materialized
	not materialized
	test column truncation
	test truncation within column
	num_rows
	num_columns
	column_width

XFrame.to_str (to be tested) (2h)

XFrame.getitem (square bracket syntax) (to be tested) (2h)
	index by XArray
	slice [a:b]
	slice [a:]
	slice [-1]
	slice [a:-b]

XFrame.groupby
	quantile (not implemented)

XFrame.save (1h)
	csv (to be tested)	

XFrame.split_datetime (not implemented) (*)
	good date-time
	bad date-time

XArray
------

Implement and test datetime as a primitive datatype (*)
Add test cases to many existing test classes

XArray.count_words (not implemented)  (4h)

XArray.count_ngrams (not implemented) (4h)

XArray.filter (to be tested) (2h)

XArray.save_as_text (to be tested; on nonlocal filesystem) (2h)

XArray.datetime_to_str (not implemented) (*)

XArray.strToDatetime (not implemented) (*)

XArray.sketch_summary
	separate tests for numeric and nonnumeric:
		quantile (to be tested)
		size (to be tested)
		num_undefined (to be tested)
		min, max, mean, var, std (to be tested)
		num_unique (to be tested)	
		frequent_items (to be tested)
		frequency_count (not implemented)
		element_summary (not implemented)
		dict_key_summary (not implemented)
		dict_value_summary (not implemented)
	sub_sketch (not implemented)
		approx 10 tests



Future Development Opportunities
--------------------------------

XGraph (16 API functions) (Graph data structure, built upon XFrame)

Image data type (jpg etc as XArray and XFrame data)

Connectors: (built upon spark data connectors)
	Avro
	SQL 
	Hive Data Files (various formats) (test)

Toolkit
	save and load models

	classifiers (create, configure, train, apply, measure) (many models)
	clustering (create, configure, train, apply, measure)
	nearest neighbor (create, configure, train, apply, measure)
	regression (create, configure, train, apply, measure)

	deep learning
	auto tagger
	data matching
	deduplication
	reccommender
	model parameter search

	image analysis (load, resize)
	graph analytics (connected components, graph coloring, k-core, pagerank, 
	    shortest path, triangle counting)
	text_analytics (term frequency transformations, topic models, count words, 
	    count_ngrams, stopwords, etc
	distance measures (euclidian, manhattan, cosine, dot product, jaccard, 
	    weighted jaccard, levenshtein, etc)


Other Work Items
----------------
Performance measurement and improvement
    detect and reduce repeated computation of RDDs by intelligent caching
    eliminate exponental growth of lazy execution plans
    reduce or eliminate zipWithIndex, because it disrupts lazy execution

Better Error reporting (lazy evaluation makes errors hard to pinpoint, 
       error messages in terms of spark are not meaningful to end user)
      hide spark stack dumps
      better checking to reduce errors from spark layer

Installers
    standalone: install into existing pySpark environment
    xpatterns: install into xpatterns ipython notebook environment

MLlib integration
    classifier
    regression

Integration with other xpatterns components
    transformations
    use from xpatterns ipython notebook

Testing
    test with localhost cluster
    identify test speed bottleneck

Example Code
    xframes tutorial notebooks (learn xframes)
    end-to-end tutorial notebooks using xframes and some ML library or libraries
        (focus on solving a problem using sample data)


Before Release
--------------

Documentation
-------------
Review all sphonx documentation.
Try all documentation examples.
Eliminate or replace reference to 'Users Guide'
Replace all references to fixed URLs controlled by graphlab.
Come up with different examples.
Write library overview (index.rst, xframe.rst, xarray.rst, etc)
Write and test install instructions
    Docker on Windows, Mac, and Ubuntu
    Install egg
Make sure documentation displays in Docker and in local install.
Document how to set spark configuration properties.

Deploy
------
Build and install in PyPi (pip install)
Upload documentation to ReadTheDocs
